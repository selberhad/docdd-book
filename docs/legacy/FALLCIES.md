Dialectic-Driven Development, or DDD, is a paradigm designed for engineering with large language models (LLMs). At its core, DDD treats development as a sequence of disciplined, document-mediated phases. The process emphasizes minimalism, concise prompts, and tightly scoped transitions, with orchestration handled by a separate server layer that governs flow. That orchestration is procedural, not generative, and is best understood at a conceptual level rather than through its specific implementation.

A key motivation for DDD is the rejection of two common fallacies about LLMs: the anthropomorphic and the robotomorphic. The anthropomorphic fallacy assumes models behave like junior human developers—capable of self-reflection, reasoning about their own limitations, or offering themselves useful coaching. In practice, LLMs do not reliably generate effective guidance for themselves; they need externally authored, carefully timed instructions. The robotomorphic fallacy makes the opposite mistake, assuming models perform best with heavy structural scaffolding such as verbose JSON schemas and rigid formats, because they are “like robots.” In fact, optimally crafted natural language—short, unambiguous, and tightly scoped to the current phase—often works better than over-formalized structures. Structure still matters, but it is best expressed as procedural discipline rather than excessive syntactic formality.

DDD therefore treats LLMs as neither people nor deterministic automata. Instead, it engages them with what might be called “LLM-oriented rituals”: small, carefully written guides injected at the right moment. Each phase has exactly one guide, and the orchestration layer ensures that progress cannot skip ahead without passing certain gates. A spec must have testable criteria before a plan can be drafted. A plan must encode strict TDD before code is written. In execution mode, code must be reviewed and refactored before it can loop forward. These gates are not suggestions—they are enforced through external procedure, rather than through the model’s own unreliable meta-reasoning.

The paradigm also distinguishes between two operating modes. Discovery mode is optimized for learning density: the loop runs from spec to plan to toy code to extracted learnings. Reviews are light and reflective, focusing on what was discovered rather than how resilient the code is. Refactoring is optional, done only to clarify the toy model. Execution mode, by contrast, optimizes for production resilience: the cycle runs from spec to plan to code to review to refactor. Reviews here are formal and adversarial, testing correctness and maintainability. Refactoring is mandatory, ensuring the architecture does not decay into incoherence. Learning is secondary in this mode, recorded only when unexpected blockers arise.

Throughout, DDD follows a principle of treating all AI-generated code as disposable drafts. Rewrites are cheap, context is valuable. The orchestration layer manages prompts to reduce drift, reinjecting project goals and assumptions only when necessary. By keeping guides canonical and prompts minimal, the system avoids context rot while still ensuring rigor.

What makes DDD effective is not simply the structure of its phases, but the philosophy underpinning it. Short, phase-specific prompts reduce ambiguity and exploit the strengths of language models. Externalized process prevents drift into vague or untestable work. Separating discovery from execution avoids conflating exploration with productionization. And by focusing on natural language as the medium of control—while keeping orchestration procedural—DDD delivers results that are both more reliable and more efficient than ad-hoc prompting or schema-heavy pseudo-programming.

In the end, DDD reframes AI-assisted development as a disciplined, document-first process. It assumes neither a human-like model nor a robot-like one, but instead treats the LLM as what it is: a statistical language engine best engaged with precise, timely, and minimal instructions. That pragmatic perspective is what makes the paradigm work.